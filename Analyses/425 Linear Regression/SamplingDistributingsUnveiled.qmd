---
title: "SamplingDistributionsUnveiled"
format:
  html:
    embed-resources: true
    code-fold: true
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.height=3)

library(tidyverse) 
library(latex2exp)
library(cowplot)
library(pander)
#library(mosaic)

theme_set(theme_minimal()) 

set.seed(616)
N <- 5000
beta0 <- 3
beta1 <- 2.5

sigma <- 1.2

X <- rnorm(N, 30, 5)
Y <- beta0 + beta1*X + rnorm(N, 0, sigma)
```

## Sampling Distributions of the Slope and Intercept of a Regression Line

A sampling distribution is what you get when you take many samples of the same population. It allows us to explore the behavior of some statistic. Our understanding of sampling distributions allow us to infer what is true for population and how wrong we could be.

A researcher investigated whether the number of cute animal photos stored on a phone could predict the total storage used.
$$
    \underbrace{Y_i}_\text{Storage Used in GB} = \overbrace{\beta0}^\text{`r beta0` GB} + \overbrace{\beta1}^\text{`r beta1`} \underbrace{X_i}_\text{Photos} + \epsilon_i \quad \text{where} \ \epsilon_i \sim N(0,\overbrace{\sigma^2}^\text{`r sigma` GB^2})
    $$
        
The plots below show 3 separate samples from the population.
```{r samples, eval=TRUE, fig.height=4}
# create samples
n <- 100
mysample1 <- sample(N, n)
mysample2 <- sample(N, n)
mysample3 <- sample(N, n)

# create lm for samples
mylm1 <- lm(Y[mysample1] ~ X[mysample1])
mylm2 <- lm(Y[mysample2] ~ X[mysample2])
mylm3 <- lm(Y[mysample3] ~ X[mysample3])

# summarize samples
# summary(mylm1)
# summary(mylm2)
# summary(mylm3)

# set up for 3 plots
#par(mfrow = c(1,3))

# create plots
plot(Y[mysample1] ~ X[mysample1], col="hotpink", pch=16,
     main="Sample 1", xlab="Photos", ylab="Storage Used")
abline(mylm1, col="hotpink")
pander(mylm1, caption = "Sample 1",
       covariate.labels = c("Intercept", "Photos"))

plot(Y[mysample2] ~ X[mysample2], col="skyblue", pch=16,
     main="Sample 2", xlab="Photos", ylab="Storage Used")
abline(mylm2, col="skyblue")
pander(mylm2, caption = "Sample 2",
       covariate.labels = c("Intercept", "Photos"))

plot(Y[mysample3] ~ X[mysample3], col="green", pch=16,
     main="Sample 3", xlab="Photos", ylab="Storage Used")
abline(mylm3, col="green")
pander(mylm3, caption = "Sample 3",
       covariate.labels = c("Intercept", "Photos"))

```


-   Demonstrate how the sampling distribution is obtained for several thousand samples of both the slope and the intercept estimates and in your regression context.

-   Clearly explain what the mean and standard deviation (often called the standard error) are for each of these two distributions.

-   Most importantly, provide thorough explanation of what the standard error of your three summary output's from before measure with regards to the sampling distributions.

-   Show how the standard error is effected by the (1) sample size, (2) the value of sigma you choose, and (3) the range of the x-values. maybe 3 plots with differennt numbers

<br>

## P-values

-   Demonstrate how the **standard errors** of the sampling distributions for both the slope and intercept estimates are used to obtain p-values for the tests of hypotheses about andÂ (the true intercept and slope of the regression model).

-   Discuss why this works.

-   Reveal the logic behind the p-value.

-   Show the equation of the t-value and how to use the pt(...) function in R to convert a t-value to a two-sided p-value.

-   Show that you can calculate yourself the p-value shown in one of your summary outputs from above.

<br>

## Confidence Intervals

-   Demonstrate how the **standard errors** of each sampling distribution are used to create confidence intervals for the true regression intercept, , and true regression slope, .

-   Explain what a confidence interval really is... explain why it captures the true parameter values "95% of the time."

-   Show how to use the qt(...) function in R to obtain the critical value t\* of the confidence interval.

-   Show the equation of the confidence interval and explain how it is using the standard error of the sampling distribution.

-   Match the results of confint(mylm) using qt(...) and the standard error from one of your regression summary outputs to calculate the same confidence interval yourself.
