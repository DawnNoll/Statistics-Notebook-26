---
title: "SamplingDistributionsUnveiled"
format:
  html:
    embed-resources: true
    code-fold: true
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.height=3)

library(tidyverse) 
library(latex2exp)
#library(cowplot)
library(pander)
#library(mosaic) 

theme_set(theme_minimal()) 
```

## Sampling Distributions of the Slope and Intercept of a Regression Line

A sampling distribution is what you get when you take many samples of the same population. It essentially allows us to explore the behavior of some statistic. Our understanding of sampling distributions allow us to infer what is true for population and how wrong we could be.

```{r samples, eval=TRUE}
set.seed(616)
N <- 5000
beta0 <- 3
beta1 <- 2.5

sigma <- 1.2

X <- rnorm(N, 30, 5)
Y <- beta0 + beta1*X + rnorm(N, 0, sigma)

#plot(Y ~ X, col=rgb(.1,.1,.1,.01), pch=16)

n <- 100
mysample1 <- sample(N, n)
mysample2 <- sample(N, n)
mysample3 <- sample(N, n)

plot(Y[mysample1] ~ X[mysample1], col="hotpink", pch=16)
mylm1 <- lm(Y[mysample1] ~ X[mysample1])
summary(mylm1)
abline(mylm1, col="hotpink")

plot(Y[mysample2] ~ X[mysample2], col="skyblue", pch=16)
mylm2 <- lm(Y[mysample2] ~ X[mysample2])
summary(mylm2)
abline(mylm2, col="skyblue")

plot(Y[mysample3] ~ X[mysample3], col="green", pch=16)
mylm3 <- lm(Y[mysample3] ~ X[mysample3])
summary(mylm3)
abline(mylm3, col="green")

pander(mylm1, caption = "Sample 1")
pander(mylm2, caption = "Sample 2")
pander(mylm3, caption = "Sample 3")
```
What is the two-sided p-value for a t-value of 1.285 when there are 13 degrees of freedom?
```{r}
curve(dt(x, 3), from=-4, to=4, lwd=2)
   curve(dnorm(x), add=TRUE, col="gray")
   abline(h=0, v=c(-1,1), col=c("gray","orange","orange"), lwd=c(1,2,2))
# What is the two-sided p-value for a t-value of 2.991 when there are 48 degrees of freedom? 
   pt(-abs(2.991), 48)*2 #gives the area more extreme than t=-1 for t-dist with 3 df.
   
#Change the area of the percentile to be 0.975 (the 97.5 percentile).

#You should get the t-value of 2.011, which can be obtained in R by the code:
# subtract the area from the t-value?
# the area/percentile is the confidence value and the t-v is the critical value
qt(1-0.05/2, 48)
#What is the critical value for 90% confidence in a t distribution with 13 degrees of freedom? Show the answer using both the online applet and using R. 
qt(1-.1/2, 13)
tvalue how far your slop/int is from hyp one
tstar the number of standard dev from mean to capture 95
pt(-abs(-2.601), 48)*2

cars.lm <- lm(dist ~ speed, data=cars)
summary(cars.lm)
confint(cars.lm)
#b0+-t*sd
-17.5791+(-2.011*6.7584)
-17.5791-(-2.011*6.7584)
qt(.975,48) t* tstar
```

-   A researcher investigated whether the number of cute animal photos stored on a phone could predict the total storage used.

    $$ \underbrace{Y_i}_\text{Storage Used in GB} = \overbrace{\beta_0}^\text{`r beta0` GB} + \overbrace{\beta1}^\text{`r beta1` } \underbrace{X_i}_\text{Photos} + \epsilon_i \quad \text{where} \ \epsilon_i \sim N(0,\overbrace{\sigma^2}^\text{`r sigma` GB^2}) $$

    ```         
    ```

-   Show scatterplots and regression summary's for three different samples of data (of a given sample size) from your population. *shows all samples are wrong and none agree*

-   Demonstrate how the sampling distribution is obtained for several thousand samples of both the slope and the intercept estimates and in your regression context.

-   Clearly explain what the mean and standard deviation (often called the standard error) are for each of these two distributions.

-   Most importantly, provide thorough explanation of what the standard error of your three summary output's from before measure with regards to the sampling distributions.

-   Show how the standard error is effected by the (1) sample size, (2) the value of sigma you choose, and (3) the range of the x-values. maybe 3 plots with differennt numbers

<br>

## P-values

-   Demonstrate how the **standard errors** of the sampling distributions for both the slope and intercept estimates are used to obtain p-values for the tests of hypotheses about andÂ (the true intercept and slope of the regression model).

-   Discuss why this works.

-   Reveal the logic behind the p-value.

-   Show the equation of the t-value and how to use the pt(...) function in R to convert a t-value to a two-sided p-value.

-   Show that you can calculate yourself the p-value shown in one of your summary outputs from above.

<br>

## Confidence Intervals

-   Demonstrate how the **standard errors** of each sampling distribution are used to create confidence intervals for the true regression intercept, , and true regression slope, .

-   Explain what a confidence interval really is... explain why it captures the true parameter values "95% of the time."

-   Show how to use the qt(...) function in R to obtain the critical value t\* of the confidence interval.

-   Show the equation of the confidence interval and explain how it is using the standard error of the sampling distribution.

-   Match the results of confint(mylm) using qt(...) and the standard error from one of your regression summary outputs to calculate the same confidence interval yourself.
